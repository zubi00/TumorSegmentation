import osimport randomfrom pathlib import Pathimport numpy as npimport torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import Dataset, DataLoaderimport pytorch_lightning as plfrom pytorch_lightning.callbacks import ModelCheckpointfrom pytorch_lightning.loggers import TensorBoardLoggerimport matplotlib.pyplot as pltfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_scoreimport seaborn as snsclass LungTumorDataset(Dataset):    def __init__(self, data_dir, transform=None):        self.data_dir = Path(data_dir)        self.ct_slices = sorted(list(self.data_dir.glob("ct_slice_*.npy")))        self.masks = sorted(list(self.data_dir.glob("mask_mask_*.npy")))        self.transform = transform    def __len__(self):        return len(self.ct_slices)    def __getitem__(self, idx):        ct_slice = np.load(self.ct_slices[idx])        mask = np.load(self.masks[idx])                ct_slice = torch.from_numpy(ct_slice).float().unsqueeze(0)        mask = torch.from_numpy(mask).long()                if self.transform:            ct_slice = self.transform(ct_slice)                return ct_slice, maskclass DualAttentionModule(nn.Module):    def __init__(self, in_channels):        super(DualAttentionModule, self).__init__()        self.channel_attention = ChannelAttention(in_channels)        self.spatial_attention = SpatialAttention()    def forward(self, x):        x = self.channel_attention(x)        x = self.spatial_attention(x)        return xclass ChannelAttention(nn.Module):    def __init__(self, in_channels, ratio=16):        super(ChannelAttention, self).__init__()        self.avg_pool = nn.AdaptiveAvgPool2d(1)        self.max_pool = nn.AdaptiveMaxPool2d(1)        self.fc1 = nn.Conv2d(in_channels, in_channels // ratio, 1, bias=False)        self.relu = nn.ReLU()        self.fc2 = nn.Conv2d(in_channels // ratio, in_channels, 1, bias=False)        self.sigmoid = nn.Sigmoid()    def forward(self, x):        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))        out = avg_out + max_out        return x * self.sigmoid(out)class SpatialAttention(nn.Module):    def __init__(self, kernel_size=7):        super(SpatialAttention, self).__init__()        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)        self.sigmoid = nn.Sigmoid()    def forward(self, x):        avg_out = torch.mean(x, dim=1, keepdim=True)        max_out, _ = torch.max(x, dim=1, keepdim=True)        x = torch.cat([avg_out, max_out], dim=1)        x = self.conv(x)        return x * self.sigmoid(x)class MultipleAttentionGateModule(nn.Module):    def __init__(self, F_g, F_l, F_int):        super(MultipleAttentionGateModule, self).__init__()        self.W_g = nn.Sequential(            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),            nn.BatchNorm2d(F_int)        )        self.W_x = nn.Sequential(            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),            nn.BatchNorm2d(F_int)        )        self.psi = nn.Sequential(            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),            nn.BatchNorm2d(1),            nn.Sigmoid()        )        self.relu = nn.ReLU(inplace=True)    def forward(self, g, x):        g1 = self.W_g(g)        x1 = self.W_x(x)        psi = self.relu(g1 + x1)        psi = self.psi(psi)        return x * psiclass AttentionUNet(nn.Module):    def __init__(self, in_channels=1, out_channels=2):        super(AttentionUNet, self).__init__()        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)        self.conv1 = self.conv_block(in_channels, 64)        self.conv2 = self.conv_block(64, 128)        self.conv3 = self.conv_block(128, 256)        self.conv4 = self.conv_block(256, 512)        self.conv5 = self.conv_block(512, 1024)        self.up5 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)        self.att5 = MultipleAttentionGateModule(F_g=512, F_l=512, F_int=256)        self.upconv5 = self.conv_block(1024, 512)        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)        self.att4 = MultipleAttentionGateModule(F_g=256, F_l=256, F_int=128)        self.upconv4 = self.conv_block(512, 256)        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)        self.att3 = MultipleAttentionGateModule(F_g=128, F_l=128, F_int=64)        self.upconv3 = self.conv_block(256, 128)        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)        self.att2 = MultipleAttentionGateModule(F_g=64, F_l=64, F_int=32)        self.upconv2 = self.conv_block(128, 64)        self.conv_1x1 = nn.Conv2d(64, out_channels, kernel_size=1, stride=1, padding=0)        self.dam1 = DualAttentionModule(64)        self.dam2 = DualAttentionModule(128)        self.dam3 = DualAttentionModule(256)        self.dam4 = DualAttentionModule(512)        self.dam5 = DualAttentionModule(1024)    def conv_block(self, in_channels, out_channels):        return nn.Sequential(            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),            nn.BatchNorm2d(out_channels),            nn.ReLU(inplace=True),            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),            nn.BatchNorm2d(out_channels),            nn.ReLU(inplace=True)        )    def forward(self, x):        # Encoder        x1 = self.conv1(x)        x1 = self.dam1(x1)        x2 = self.maxpool(x1)        x2 = self.conv2(x2)        x2 = self.dam2(x2)        x3 = self.maxpool(x2)        x3 = self.conv3(x3)        x3 = self.dam3(x3)        x4 = self.maxpool(x3)        x4 = self.conv4(x4)        x4 = self.dam4(x4)        x5 = self.maxpool(x4)        x5 = self.conv5(x5)        x5 = self.dam5(x5)        # Decoder        d5 = self.up5(x5)        x4 = self.att5(g=d5, x=x4)        d5 = torch.cat((x4, d5), dim=1)        d5 = self.upconv5(d5)        d4 = self.up4(d5)        x3 = self.att4(g=d4, x=x3)        d4 = torch.cat((x3, d4), dim=1)        d4 = self.upconv4(d4)        d3 = self.up3(d4)        x2 = self.att3(g=d3, x=x2)        d3 = torch.cat((x2, d3), dim=1)        d3 = self.upconv3(d3)        d2 = self.up2(d3)        x1 = self.att2(g=d2, x=x1)        d2 = torch.cat((x1, d2), dim=1)        d2 = self.upconv2(d2)        out = self.conv_1x1(d2)        return outclass AttentionUNetLightning(pl.LightningModule):    def __init__(self, in_channels=1, out_channels=2, learning_rate=1e-3):        super().__init__()        self.model = AttentionUNet(in_channels, out_channels)        self.learning_rate = learning_rate        self.criterion = nn.CrossEntropyLoss()    def forward(self, x):        return self.model(x)    def training_step(self, batch, batch_idx):        x, y = batch        y_hat = self(x)        loss = self.criterion(y_hat, y)        self.log('train_loss', loss)        return loss    def validation_step(self, batch, batch_idx):        x, y = batch        y_hat = self(x)        loss = self.criterion(y_hat, y)        self.log('val_loss', loss)        return loss    def configure_optimizers(self):        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)        return optimizerdef dice_coefficient(pred, target):    smooth = 1e-5    num = pred.size(0)    pred = pred.view(num, -1)    target = target.view(num, -1)    intersection = (pred * target).sum(1)    union = pred.sum(1) + target.sum(1)    dice = (2. * intersection + smooth) / (union + smooth)    return dice.mean()def iou_score(pred, target, threshold=0.5):    pred = (pred > threshold).float()    intersection = (pred * target).sum()    union = pred.sum() + target.sum() - intersection    return (intersection + 1e-5) / (union + 1e-5)def compute_metrics(all_preds, all_masks, thresholds=[0.5, 0.6, 0.7, 0.8, 0.9]):    metrics = {}    all_preds = np.array(all_preds)    all_masks = np.array(all_masks)        metrics['accuracy'] = accuracy_score(all_masks, all_preds > 0.5)    metrics['sensitivity'] = recall_score(all_masks, all_preds > 0.5, average='binary', pos_label=1)    metrics['specificity'] = recall_score(all_masks, all_preds > 0.5, average='binary', pos_label=0)    metrics['precision'] = precision_score(all_masks, all_preds > 0.5, average='binary')    metrics['recall'] = recall_score(all_masks, all_preds > 0.5, average='binary')    metrics['f1_score'] = f1_score(all_masks, all_preds > 0.5, average='binary')    metrics['dcs'] = dice_coefficient(torch.tensor(all_preds), torch.tensor(all_masks))        iou_scores = []    for threshold in thresholds:        iou = iou_score(torch.tensor(all_preds), torch.tensor(all_masks), threshold)        iou_scores.append(iou.item())    metrics['iou_scores'] = iou_scores        return metricsdef main():    pl.seed_everything(42)     train_dir = Path("/Users/zubairsaeed/Downloads/PhD/Code/1.Segmentation/Data/Dataset/Preprocessed/segmentation_data/train")    val_dir = Path("/Users/zubairsaeed/Downloads/PhD/Code/1.Segmentation/Data/Dataset/Preprocessed/segmentation_data/val")    train_dataset = LungTumorDataset(train_dir)    val_dataset = LungTumorDataset(val_dir)    # Create data loaders    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=6, persistent_workers=True)    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=6, persistent_workers=True)    model = AttentionUNetLightning()    checkpoint_callback = ModelCheckpoint(        dirpath='checkpoints',        filename='attention_unet-{epoch:02d}-{val_loss:.2f}',        save_top_k=3,        monitor='val_loss',        mode='min'    )    logger = TensorBoardLogger("lightning_logs", name="attention_unet")    device = torch.device("mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")    trainer = pl.Trainer(        max_epochs=100,        callbacks=[checkpoint_callback],        logger=logger,        accelerator='auto',        devices=1 if device.type in ['cuda', 'mps'] else None    )    trainer.fit(model, train_loader, val_loader)    model.eval()    val_dice_score = 0    all_preds = []    all_masks = []    all_confidences = []    with torch.no_grad():        for ct_slices, masks in val_loader:            ct_slices, masks = ct_slices.to(model.device)if __name__ == '__main__':    main()