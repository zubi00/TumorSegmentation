import osimport randomfrom pathlib import Pathimport numpy as npimport torchimport torchvisionfrom torchvision.models.detection import maskrcnn_resnet50_fpnfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictorfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictorfrom torch.utils.data import Dataset, DataLoaderimport pytorch_lightning as plfrom pytorch_lightning.callbacks import ModelCheckpointfrom pytorch_lightning.loggers import TensorBoardLoggerimport matplotlib.pyplot as pltfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_scoreimport seaborn as snsimport cv2class LungTumorDataset(Dataset):    def __init__(self, data_dir, transform=None):        self.data_dir = Path(data_dir)        self.ct_slices = sorted(list(self.data_dir.glob("ct_slice_*.npy")))        self.masks = sorted(list(self.data_dir.glob("mask_mask_*.npy")))        self.transform = transform    def __len__(self):        return len(self.ct_slices)    def __getitem__(self, idx):        ct_slice = np.load(self.ct_slices[idx])        mask = np.load(self.masks[idx])                ct_slice = torch.from_numpy(ct_slice).float().unsqueeze(0)        mask = torch.from_numpy(mask).long()                if self.transform:            ct_slice = self.transform(ct_slice)                # Convert to the format expected by Mask R-CNN        boxes = self.get_bounding_boxes(mask)        num_objs = len(boxes)                target = {}        target["boxes"] = boxes        target["labels"] = torch.ones((num_objs,), dtype=torch.int64)  # all objects are tumor (class 1)        target["masks"] = mask.unsqueeze(0)        target["image_id"] = torch.tensor([idx])        target["area"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])        target["iscrowd"] = torch.zeros((num_objs,), dtype=torch.int64)                return ct_slice, target    def get_bounding_boxes(self, mask):        # Find contours in the mask        contours, _ = cv2.findContours(mask.numpy().astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)                boxes = []        for contour in contours:            x, y, w, h = cv2.boundingRect(contour)            boxes.append([x, y, x+w, y+h])                return torch.tensor(boxes, dtype=torch.float32)def collate_fn(batch):    return tuple(zip(*batch))class MaskRCNNLightning(pl.LightningModule):    def __init__(self, num_classes=2, learning_rate=1e-4):        super().__init__()        self.learning_rate = learning_rate                # Load pre-trained Mask R-CNN model        self.model = maskrcnn_resnet50_fpn(pretrained=True)                # Replace the classifier with a new one for our number of classes        in_features = self.model.roi_heads.box_predictor.cls_score.in_features        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)        # Replace the mask predictor with a new one        in_features_mask = self.model.roi_heads.mask_predictor.conv5_mask.in_channels        hidden_layer = 256        self.model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)    def forward(self, images, targets=None):        return self.model(images, targets)    def validation_step(self, batch, batch_idx):        images, targets = batch        loss_dict = self.model(images, targets)            if isinstance(loss_dict, list):            # If loss_dict is a list, assume it contains a single loss value            losses = sum(loss_dict)        elif isinstance(loss_dict, dict):          # If loss_dict is a dictionary, sum its values            losses = sum(loss for loss in loss_dict.values())        else:            # If it's neither a list nor a dictionary, assume it's a single tensor            losses = loss_dict            self.log('val_loss', losses)        return losses    def training_step(self, batch, batch_idx):        images, targets = batch        loss_dict = self.model(images, targets)                if isinstance(loss_dict, list):            losses = sum(loss_dict)        elif isinstance(loss_dict, dict):            losses = sum(loss for loss in loss_dict.values())        else:            losses = loss_dict            self.log('train_loss', losses)        return losses    def configure_optimizers(self):        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)        return optimizerdef dice_coefficient(pred, target):    smooth = 1e-5    intersection = (pred * target).sum()    union = pred.sum() + target.sum()    dice = (2. * intersection + smooth) / (union + smooth)    return dicedef iou_score(pred, target, threshold=0.5):    pred = (pred > threshold).float()    intersection = (pred * target).sum()    union = pred.sum() + target.sum() - intersection    return (intersection + 1e-5) / (union + 1e-5)def compute_metrics(all_preds, all_masks, thresholds=[0.5, 0.6, 0.7, 0.8, 0.9]):    metrics = {}    metrics['accuracy'] = accuracy_score(all_masks.flatten(), all_preds.flatten() > 0.5)    metrics['sensitivity'] = recall_score(all_masks.flatten(), all_preds.flatten() > 0.5, average='binary', pos_label=1)    metrics['specificity'] = recall_score(all_masks.flatten(), all_preds.flatten() > 0.5, average='binary', pos_label=0)    metrics['precision'] = precision_score(all_masks.flatten(), all_preds.flatten() > 0.5, average='binary')    metrics['recall'] = recall_score(all_masks.flatten(), all_preds.flatten() > 0.5, average='binary')    metrics['f1_score'] = f1_score(all_masks.flatten(), all_preds.flatten() > 0.5, average='binary')    metrics['dcs'] = dice_coefficient(torch.tensor(all_preds), torch.tensor(all_masks))        iou_scores = []    for threshold in thresholds:        iou = iou_score(torch.tensor(all_preds), torch.tensor(all_masks), threshold)        iou_scores.append(iou.item())    metrics['iou_scores'] = iou_scores        return metricsdef main():    # Set random seed for reproducibility    pl.seed_everything(42)    # Define data paths    train_dir = Path("/Users/zubairsaeed/Downloads/PhD/Code/1.Segmentation/Data/Dataset/Preprocessed/segmentation_data/train")    val_dir = Path("/Users/zubairsaeed/Downloads/PhD/Code/1.Segmentation/Data/Dataset/Preprocessed/segmentation_data/val")    # Create datasets    train_dataset = LungTumorDataset(train_dir)    val_dataset = LungTumorDataset(val_dir)    # Create data loaders    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=1, collate_fn=collate_fn)    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=1, collate_fn=collate_fn)    # Initialize model    model = MaskRCNNLightning()    # Define callbacks    checkpoint_callback = ModelCheckpoint(        dirpath='checkpoints',        filename='maskrcnn-{epoch:02d}-{val_loss:.2f}',        save_top_k=3,        monitor='val_loss',        mode='min'    )    # Define logger    logger = TensorBoardLogger("lightning_logs", name="maskrcnn")    # Initialize trainer    device = torch.device("mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")    trainer = pl.Trainer(        max_epochs=100,        callbacks=[checkpoint_callback],        logger=logger,        accelerator='auto',        devices=1 if device.type in ['cuda', 'mps'] else None    )    # Train the model    trainer.fit(model, train_loader, val_loader)    # Evaluate on validation set    model.eval()    all_preds = []    all_masks = []    all_confidences = []    with torch.no_grad():        for images, targets in val_loader:            images = list(image.to(model.device) for image in images)            outputs = model(images)                        for i, output in enumerate(outputs):                pred_mask = output['masks'][0, 0].cpu()                true_mask = targets[i]['masks'][0].cpu()                confidence = output['scores'][0].item()                                all_preds.append(pred_mask.numpy())                all_masks.append(true_mask.numpy())                all_confidences.append(confidence)    all_preds = np.array(all_preds)    all_masks = np.array(all_masks)    # Compute metrics    metrics = compute_metrics(all_preds, all_masks)    for key, value in metrics.items():        if key != 'iou_scores':            print(f"{key.capitalize()}: {value:.4f}")        print("IOU Scores:")    for threshold, iou in zip([0.5, 0.6, 0.7, 0.8, 0.9], metrics['iou_scores']):        print(f"  Threshold {threshold}: {iou:.4f}")    # Plot confusion matrix    cm = confusion_matrix(all_masks.flatten(), all_preds.flatten() > 0.5)    plt.figure(figsize=(8, 6))    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')    plt.xlabel('Predicted')    plt.ylabel('True')    plt.title('Confusion Matrix')    plt.show()    # Box plot of metrics    plt.figure(figsize=(10, 6))    sns.boxplot(data=[metrics['accuracy'], metrics['sensitivity'], metrics['specificity'],                      metrics['precision'], metrics['recall'], metrics['f1_score'],                      metrics['dcs']] + metrics['iou_scores'])    plt.xticks(range(13), ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'Recall',                           'F1-score', 'DCS'] + [f'IOU-{t}' for t in [0.5, 0.6, 0.7, 0.8, 0.9]])    plt.title('Distribution of Metrics')    plt.show()    # Visualize some predictions    def visualize_prediction(image, true_mask, pred_mask, confidence):        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))        ax1.imshow(image.squeeze(), cmap='bone')        ax1.set_title('CT Slice')        ax1.axis('off')                ax2.imshow(image.squeeze(), cmap='bone')        ax2.imshow(true_mask, alpha=0.5, cmap='autumn')        ax2.set_title('True Mask')        ax2.axis('off')                ax3.imshow(image.squeeze(), cmap='bone')        ax3.imshow(pred_mask, alpha=0.5, cmap='autumn')        ax3.set_title(f'Predicted Mask\nConfidence: {confidence:.4f}')        ax3.axis('off')                plt.tight_layout()        plt.show()    # Visualize 3 random validation predictions    model.eval()    with torch.no_grad():        indices = random.sample(range(len(val_dataset)), 3)        for i in indices:            image, target = val_dataset[i]            image = image.unsqueeze(0).to(model.device)            output = model(image)[0]            pred_mask = output['masks'][0, 0].cpu().numpy()            pred_mask = (pred_mask > 0.5).astype(np.uint8)            true_mask = target['masks'][0].numpy()            confidence = output['scores'][0].item()                        visualize_prediction(image.cpu().squeeze(), true_mask, pred_mask, confidence)if __name__ == '__main__':    main()