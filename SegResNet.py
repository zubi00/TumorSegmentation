import osimport randomfrom pathlib import Pathimport numpy as npimport torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import Dataset, DataLoaderimport pytorch_lightning as plfrom pytorch_lightning.callbacks import ModelCheckpointfrom pytorch_lightning.loggers import TensorBoardLoggerimport matplotlib.pyplot as pltfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_scoreimport seaborn as snsclass LungTumorDataset(Dataset):    def __init__(self, data_dir, transform=None):        self.data_dir = Path(data_dir)        self.ct_slices = sorted(list(self.data_dir.glob("ct_slice_*.npy")))        self.masks = sorted(list(self.data_dir.glob("mask_mask_*.npy")))        self.transform = transform    def __len__(self):        return len(self.ct_slices)    def __getitem__(self, idx):        ct_slice = np.load(self.ct_slices[idx])        mask = np.load(self.masks[idx])                ct_slice = torch.from_numpy(ct_slice).float().unsqueeze(0)        mask = torch.from_numpy(mask).long()                if self.transform:            ct_slice = self.transform(ct_slice)                return ct_slice, maskclass ResidualBlock(nn.Module):    def __init__(self, in_channels, out_channels):        super(ResidualBlock, self).__init__()        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)        self.bn1 = nn.BatchNorm2d(out_channels)        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)        self.bn2 = nn.BatchNorm2d(out_channels)        self.relu = nn.ReLU(inplace=True)        self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None    def forward(self, x):        residual = x        out = self.conv1(x)        out = self.bn1(out)        out = self.relu(out)        out = self.conv2(out)        out = self.bn2(out)        if self.downsample:            residual = self.downsample(x)        out += residual        out = self.relu(out)        return outclass SegResNet(nn.Module):    def __init__(self, in_channels=1, out_channels=2):        super(SegResNet, self).__init__()                self.encoder = nn.Sequential(            self.make_layer(in_channels, 64),            self.make_layer(64, 128),            self.make_layer(128, 256),            self.make_layer(256, 512),        )                self.decoder = nn.Sequential(            self.make_layer(512, 256, transpose=True),            self.make_layer(256, 128, transpose=True),            self.make_layer(128, 64, transpose=True),            nn.ConvTranspose2d(64, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),        )            def make_layer(self, in_channels, out_channels, transpose=False):        layers = []        if transpose:            layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1))        else:            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1))        layers.append(ResidualBlock(out_channels, out_channels))        return nn.Sequential(*layers)        def forward(self, x):        features = []        for encoder_layer in self.encoder:            x = encoder_layer(x)            features.append(x)                features = features[::-1]                for i, decoder_layer in enumerate(self.decoder):            x = decoder_layer(x)            if i < len(self.decoder) - 1:                x = x + features[i+1]                return xclass SegResNetLightning(pl.LightningModule):    def __init__(self, in_channels=1, out_channels=2, learning_rate=1e-3):        super().__init__()        self.model = SegResNet(in_channels, out_channels)        self.learning_rate = learning_rate        self.criterion = nn.CrossEntropyLoss()    def forward(self, x):        return self.model(x)    def training_step(self, batch, batch_idx):        x, y = batch        y_hat = self(x)        loss = self.criterion(y_hat, y)        self.log('train_loss', loss)        return loss    def validation_step(self, batch, batch_idx):        x, y = batch        y_hat = self(x)        loss = self.criterion(y_hat, y)        self.log('val_loss', loss)        return loss    def configure_optimizers(self):        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)        return optimizerdef dice_coefficient(pred, target):    smooth = 1e-5    num = pred.size(0)    pred = pred.view(num, -1)    target = target.view(num, -1)    intersection = (pred * target).sum(1)    union = pred.sum(1) + target.sum(1)    dice = (2. * intersection + smooth) / (union + smooth)    return dice.mean()def iou_score(pred, target, threshold=0.5):    pred = (pred > threshold).float()    intersection = (pred * target).sum()    union = pred.sum() + target.sum() - intersection    return (intersection + 1e-5) / (union + 1e-5)def compute_metrics(all_preds, all_masks, thresholds=[0.5, 0.6, 0.7, 0.8, 0.9]):    metrics = {}        # Ensure all_preds and all_masks are numpy arrays    all_preds = np.array(all_preds)    all_masks = np.array(all_masks)        # Flatten and binarize predictions    all_preds_flat = all_preds.flatten() > 0.5    all_masks_flat = all_masks.flatten()    metrics['accuracy'] = accuracy_score(all_masks_flat, all_preds_flat)    metrics['sensitivity'] = recall_score(all_masks_flat, all_preds_flat, average='binary', pos_label=1)    metrics['specificity'] = recall_score(all_masks_flat, all_preds_flat, average='binary', pos_label=0)    metrics['precision'] = precision_score(all_masks_flat, all_preds_flat, average='binary')    metrics['recall'] = recall_score(all_masks_flat, all_preds_flat, average='binary')    metrics['f1_score'] = f1_score(all_masks_flat, all_preds_flat, average='binary')    metrics['dcs'] = dice_coefficient(torch.tensor(all_preds), torch.tensor(all_masks))        iou_scores = []    for threshold in thresholds:        iou = iou_score(torch.tensor(all_preds), torch.tensor(all_masks), threshold)        iou_scores.append(iou.item())    metrics['iou_scores'] = iou_scores        return metricsdef main():    # Set random seed for reproducibility    pl.seed_everything(42)    # Define data paths    train_dir = Path("/Users/zubairsaeed/Downloads/PhD/Code/1.Segmentation/Data/Dataset/Preprocessed/segmentation_data/train")    val_dir = Path("/Users/zubairsaeed/Downloads/PhD/Code/1.Segmentation/Data/Dataset/Preprocessed/segmentation_data/val")    # Create datasets    train_dataset = LungTumorDataset(train_dir)    val_dataset = LungTumorDataset(val_dir)    # Create data loaders    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=1, persistent_workers=True)    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=1, persistent_workers=True)    # Initialize model    model = SegResNetLightning()    # Define callbacks    checkpoint_callback = ModelCheckpoint(        dirpath='checkpoints',        filename='segresnet-{epoch:02d}-{val_loss:.2f}',        save_top_k=3,        monitor='val_loss',        mode='min'    )    # Define logger    logger = TensorBoardLogger("lightning_logs", name="segresnet")    # Initialize trainer    device = torch.device("mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")    trainer = pl.Trainer(        max_epochs=200,        callbacks=[checkpoint_callback],        logger=logger,        accelerator='auto',        devices=1 if device.type in ['cuda', 'mps'] else None    )    # Train the model    trainer.fit(model, train_loader, val_loader)    # Evaluate on validation set    model.eval()    val_dice_score = 0    all_preds = []    all_masks = []    all_confidences = []    with torch.no_grad():        for ct_slices, masks in val_loader:            ct_slices, masks = ct_slices.to(model.device), masks.to(model.device)            outputs = model(ct_slices)            preds = torch.argmax(outputs, dim=1)            confidences = torch.softmax(outputs, dim=1)[:, 1]  # Confidence for positive class            val_dice_score += dice_coefficient(preds, masks)                        all_preds.extend(preds.cpu().numpy().flatten())            all_masks.extend(masks.cpu().numpy().flatten())            all_confidences.extend(confidences.cpu().numpy().flatten())    val_dice_score /= len(val_loader)    print(f"Validation Dice Score: {val_dice_score:.4f}")    # Compute metrics    metrics = compute_metrics(all_preds, all_masks)    for key, value in metrics.items():        if key != 'iou_scores':            print(f"{key.capitalize()}: {value:.4f}")        print("IOU Scores:")    for threshold, iou in zip([0.5, 0.6, 0.7, 0.8, 0.9], metrics['iou_scores']):        print(f"  Threshold {threshold}: {iou:.4f}")    # Plot confusion matrix    cm = confusion_matrix(all_masks, all_preds)    plt.figure(figsize=(8, 6))    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')    plt.xlabel('Predicted')    plt.ylabel('True')    plt.title('Confusion Matrix')    plt.show()    # Box plot of metrics    plt.figure(figsize=(12, 6))    metric_names = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'Recall', 'F1-score', 'DCS'] + [f'IOU-{t}' for t in [0.5, 0.6, 0.7, 0.8, 0.9]]    metric_values = [metrics['accuracy'], metrics['sensitivity'], metrics['specificity'],                     metrics['precision'], metrics['recall'], metrics['f1_score'],                     metrics['dcs']] + metrics['iou_scores']        sns.boxplot(data=metric_values)    plt.xticks(range(len(metric_names)), metric_names, rotation=45, ha='right')    plt.title('Distribution of Metrics')    plt.tight_layout()    plt.show()    # ROC curve    from sklearn.metrics import roc_curve, auc    fpr, tpr, _ = roc_curve(all_masks, all_confidences)    roc_auc = auc(fpr, tpr)    plt.figure(figsize=(8, 6))    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')    plt.xlim([0.0, 1.0])    plt.ylim([0.0, 1.05])    plt.xlabel('False Positive Rate')    plt.ylabel('True Positive Rate')    plt.title('Receiver Operating Characteristic (ROC) Curve')    plt.legend(loc="lower right")    plt.show()    # Visualize some predictions with confidence scores    def visualize_prediction(ct_slice, true_mask, pred_mask, confidence):        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))        ax1.imshow(ct_slice.squeeze(), cmap='bone')        ax1.set_title('CT Slice')        ax1.axis('off')            ax2.imshow(ct_slice.squeeze(), cmap='bone')        ax2.imshow(true_mask, alpha=0.5, cmap='autumn')        ax2.set_title('True Mask')        ax2.axis('off')            ax3.imshow(ct_slice.squeeze(), cmap='bone')        ax3.imshow(pred_mask, alpha=0.5, cmap='autumn')        ax3.set_title(f'Predicted Mask\nMean Confidence: {confidence:.4f}')        ax3.axis('off')            plt.tight_layout()        plt.show()    # Visualize 4 random validation predictions with confidence scores    model.eval()    with torch.no_grad():        indices = random.sample(range(len(val_dataset)), 4)        for i in indices:            ct_slice, true_mask = val_dataset[i]            ct_slice = ct_slice.unsqueeze(0).to(model.device)            output = model(ct_slice)            pred_mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()            confidence = torch.softmax(output, dim=1)[:, 1].mean().item()  # Mean confidence for positive class            visualize_prediction(ct_slice.cpu().squeeze(), true_mask.squeeze(), pred_mask, confidence)if __name__ == '__main__':    main()